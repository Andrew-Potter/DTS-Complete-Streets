{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DTS modal composite processing - Modal Composite 01 through 02\n",
    "## 11/3/2020\n",
    "## rmangan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import arcpy\n",
    "from arcgis import GIS\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set environment setttings\n",
    "arcpy.env.workspace = \"Z:\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_scratch.gdb\"\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Input_Data.gdb\"\n",
    "\n",
    "scratch_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_scratch.gdb\"\n",
    "\n",
    "output_gdb_path = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\modal_composite_output.gdb\"\n",
    "\n",
    "\n",
    "# Input Datasets\n",
    "#Ped_Plan = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Input_Data.gdb\\OPP_ModalPriority_081720\"\n",
    "\n",
    "Ped_Plan = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\scratch_GDBs\\OPP_domain_processing.gdb\\OPP_ModalPriority_081720_output\"\n",
    "\n",
    "Ped_Improve = os.path.join(input_gdb_path,\"OPP_CandidateUpgrades_090420Dissolve_101320\")\n",
    "\n",
    "Ped_Add = os.path.join(input_gdb_path,\"OPP_CandidateWalkways_091520Dissolve_update101620\")\n",
    "\n",
    "Bike_Exist = os.path.join(input_gdb_path,\"BIKEPLAN_Existing_Bikeways\")\n",
    "\n",
    "Bike_Proposed = os.path.join(input_gdb_path,\"BIKEPLAN_Proposed_Bikeways\")\n",
    "\n",
    "Bike_ReDev = os.path.join(input_gdb_path,\"BIKEPLAN_Redevelopment_Bikeways\")\n",
    "\n",
    "RCL = os.path.join(input_gdb_path,\"RCL_Public_Street_Centerline_20201013\")\n",
    "\n",
    "TransCAD_2020 = os.path.join(input_gdb_path,\"MPO_TRANSCAD_network2020\")\n",
    "\n",
    "TransCAD_2020_aloha_stadium = os.path.join(input_gdb_path,\"MPO_TRANSCAD_network2020_aloha_stadium\")\n",
    "\n",
    "TransCAD_2040 = os.path.join(input_gdb_path,\"MPO_TRANSCAD_network_adjusted2040\")\n",
    "\n",
    "modal_composite_02 = os.path.join(scratch_gdb_path,\"modal_composite_02a\")\n",
    "\n",
    "modal_composite_03 = r\"\\\\dc1vs01\\GISProj\\H\\Honolulu_DTS\\D3409300_RailActivation\\GeoData\\GDB\\Modal\\Modal Composite 3.gdb\\modal_composite_03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get fields\n",
    "fields = arcpy.ListFields(modal_processing_temp)\n",
    "\n",
    "for field in fields:\n",
    "    #print(field.name, field.aliasName, field.type)\n",
    "    print(field.name, field.aliasName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create num fields from 1986 text fields & parse value to new fields handle text entry via hardcoded mapping\n",
    "\n",
    "#copy input dataset while testing functions\n",
    "print(\"copying modal input for processing...\")\n",
    "modal_processing_temp = arcpy.CopyFeatures_management(modal_composite_03,\"modal_processing_temp\")\n",
    "print(\"done\")\n",
    "\n",
    "#store field, field alias in dict\n",
    "new_fields = {\"ln_exist_num\":\"1986 Existing Lanes (num)\",\n",
    "              \"ln_prop_num\": \"1986 Proposed Lanes (num)\",\n",
    "              \"row_exist_num\":\"1986 Existing ROW (num)\",\n",
    "              \"row_prop_num\":\"1986 Proposed ROW (num)\"}\n",
    "\n",
    "#loop through dict and add fields\n",
    "for key,value in new_fields.items():\n",
    "    print(\"Adding field {0}\".format(key))\n",
    "    arcpy.AddField_management(modal_processing_temp,field_name=key,field_type=\"SHORT\", field_alias = value)\n",
    "          \n",
    "print(\"Field additions complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field to expose to update cursor\n",
    "fields = [\"ln_exist\",\"ln_prop\",\"row_exist\",\"row_prop\",\"ln_exist_num\",\"ln_prop_num\", \"row_exist_num\",\"row_prop_num\"]\n",
    "\n",
    "#update ln_exist_num w/ update cursor\n",
    "print(\"parse ln_exist to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[0] == '4+ bus':\n",
    "                row[4] = 4\n",
    "            elif row[0] == '3+ bus':\n",
    "                row[4] = 3\n",
    "            else:\n",
    "                row[4]= int(row[0])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)            \n",
    "print(\"ln_exist parsed\\n\")\n",
    "            \n",
    "#update ln_prop_num w/ update cursor\n",
    "print(\"parse ln_prop to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[1] == '5+ bus':\n",
    "                row[5] = 5\n",
    "            else:\n",
    "                row[5]= int(row[1])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"ln_prop parsed\\n\")\n",
    "            \n",
    "#update row_exist_num w/ update cursor\n",
    "print(\"parse row_exist to num\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:\n",
    "            if row[2] == 'Var. to 80':\n",
    "                row[6] = 80\n",
    "            elif row[2] == 'Var. 60-70':\n",
    "                row[6] = 65\n",
    "            elif row[2] == 'Var. 36-50':\n",
    "                row[6] == 61\n",
    "            elif row[2] == 'Var. 14-26':\n",
    "                row[6] = 20\n",
    "            elif row[2] == '86/100':\n",
    "                row[6] = 93\n",
    "            elif row[2] == '60-90':\n",
    "                row[6] = 75\n",
    "            elif row[2] == '60-76':\n",
    "                row[6] = 68\n",
    "            elif row[2] == '60-70':\n",
    "                row[6] = 65\n",
    "            elif row[2] == '60-64':\n",
    "                row[6] = 62\n",
    "            elif row[2] == '50-80':\n",
    "                row[6] = 65\n",
    "            elif row[2] == '50-60':\n",
    "                row[6] = 55\n",
    "            elif row[2] == '44-56':\n",
    "                row[6] = 50\n",
    "            elif row[2] == '40/50':\n",
    "                row[6] = 45\n",
    "            elif row[2] == '40-56':\n",
    "                row[6] = 48\n",
    "            elif row[2] == '30-50':\n",
    "                row[6] = 40\n",
    "            elif row[2] == '30-40':\n",
    "                row[6] = 35\n",
    "            elif row[2] == '25-50':\n",
    "                row[6] = 38\n",
    "            elif row[2] == '20-40':\n",
    "                row[6] = 30\n",
    "            elif row[2] == '25-50':\n",
    "                row[6] = 38\n",
    "            elif row[2] == '120-140':\n",
    "                row[6] = 130\n",
    "            elif row[2] == '113.5':\n",
    "                row[6] = 114\n",
    "            elif row[2] == '100-110':\n",
    "                row[6] = 105\n",
    "            elif row[2] == '0':\n",
    "                row[6] = None\n",
    "            else:\n",
    "                row[6]= int(row[2])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"row_exist parsed\\n\")            \n",
    "                  \n",
    "#update row_prop_num w/ update cursor\n",
    "print(\"parse row_prop to int\")\n",
    "with arcpy.da.UpdateCursor(modal_processing_temp,fields,'NOT \"ln_exist\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        #print(\"row\")\n",
    "        try:          \n",
    "            if row[3] == 'Var. to 80':\n",
    "                row[7] = 80\n",
    "            elif row[3] == 'Var. 14-26':\n",
    "                row[7] = 20\n",
    "            elif row[3] == '86/100':\n",
    "                row[7] = 93\n",
    "            elif row[3] == '60-90':\n",
    "                row[7] = 75\n",
    "            elif row[3] == '60-76':\n",
    "                row[7] = 68\n",
    "            elif row[3] == '60-70':\n",
    "                row[7] = 65\n",
    "            elif row[3] == '60-64':\n",
    "                row[7] = 62\n",
    "            elif row[3] == '56-80':\n",
    "                row[7] = 68\n",
    "            elif row[3] == '50-60':\n",
    "                row[7] = 55\n",
    "            elif row[3] == '40/50':\n",
    "                row[7] = 45\n",
    "            elif row[3] == '30-40':\n",
    "                row[7] = 35\n",
    "            elif row[3] == '25-50':\n",
    "                row[7] = 38\n",
    "            elif row[3] == '120-140':\n",
    "                row[7] = 130\n",
    "            elif row[3] == '113.5':\n",
    "                row[7] = 114\n",
    "            elif row[3] == '100-110':\n",
    "                row[7] = 105\n",
    "            else:\n",
    "                row[7] = int(row[3])\n",
    "            cursor.updateRow(row)\n",
    "        except ValueError as error:\n",
    "            print(error)\n",
    "print(\"row_prop parsed\\n\")\n",
    "\n",
    "print(\"Processing Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "#Check field for unique values\n",
    "def isUniqueValueField(dataset, field):\n",
    "    #Check if a field is unique for a given dataset, return True/False\n",
    "    idList = []\n",
    "    with arcpy.da.SearchCursor(dataset, field) as cursor:\n",
    "        for row in cursor:\n",
    "            idList.append(row[0])\n",
    "    if len(idList) != len(set(idList)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#Add line length field & calculte length. Used to validate geometry is the same after joining\n",
    "def LineLength(dataset):\n",
    "    #adds \"line_length\" field to input dataset & calculates length\n",
    "    #MODIFIES INPUT DATSET\n",
    "    \n",
    "    arcpy.AddField_management(dataset, \"line_length\", \"DOUBLE\")\n",
    "    arcpy.CalculateGeometryAttributes_management(dataset,[[\"line_length\", \"LENGTH\"]])\n",
    "    \n",
    "    \n",
    "    \n",
    "def CheckMultiPart(dataset):\n",
    "    #check if a feature class contains multipart geometry, report OIDs of multipart geometry to table\n",
    "    #MODIFIES INPUT DATASET\n",
    "    \n",
    "    #get count of input features\n",
    "    input_count = arcpy.GetCount_management(dataset)\n",
    "    print(str(input_count) + \" records in input dataset\")\n",
    "\n",
    "    #add tmpUID field to input dataset\n",
    "    arcpy.AddField_management(dataset, \"tmpUID\",\"LONG\")\n",
    "    print(\"tmpUID field added to input dataset\")\n",
    "\n",
    "    #determine OID field of input dataset\n",
    "    OID_field_name = arcpy.Describe(dataset).OIDFieldName\n",
    "    print(\"OID = \" + str(OID_field_name))\n",
    "\n",
    "    #calculate OID to tmpUID\n",
    "    print(\"Calculating OID to tmpUID...\")\n",
    "    arcpy.CalculateField_management(dataset,\"tmpUID\",\"!\" + OID_field_name +\"!\")\n",
    "    print(\"OID calculated to tmpUID\")\n",
    "\n",
    "    #define singlepart dataset\n",
    "    singlepart_fc_name = str(dataset)+\"_singlepart\"\n",
    "    singlepart_fc = os.path.join(scratch_gdb_path, singlepart_fc_name)\n",
    "\n",
    "    #delete singlepart dataset if it already exists\n",
    "    if arcpy.Exists(singlepart_fc):\n",
    "        print(\"Singlepart dataset already exists, deleting...\")\n",
    "        arcpy.Delete_management(singlepart_fc)\n",
    "        print(\"Singlepart dataset deleted\")\n",
    "\n",
    "    #split input features into singlepart dataset\n",
    "    print(\"Splitting input dataset into singlepart feature...\")\n",
    "    arcpy.MultipartToSinglepart_management(dataset,singlepart_fc)\n",
    "    print(\"input exploded to singlepart\" + singlepart_fc_name)\n",
    "\n",
    "    #get feature count of output \n",
    "    output_count = arcpy.GetCount_management(singlepart_fc)\n",
    "    print(str(output_count)+ \" records in singlepart FC\")\n",
    "\n",
    "    # if multipart features found, run freq and get ID of multipart feature\n",
    "    if input_count != output_count:\n",
    "        print(\"Multipart features found.\")\n",
    "        print(\"{0} records in input, {1} records in singlepart output.\".format(input_count, output_count))\n",
    "\n",
    "        #define frequency table\n",
    "        freq_table_name = str(dataset)+\"_freq\"\n",
    "        freq_table = os.path.join(scratch_gdb_path, freq_table_name)\n",
    "\n",
    "        #delete freq table if it already exists\n",
    "        if arcpy.Exists(freq_table):\n",
    "            print(\"freq table exists, deleting...\")\n",
    "            arcpy.Delete_management(freq_table)\n",
    "            print('freq table deleted')\n",
    "\n",
    "        #run frequency analysis on singlepart dataset\n",
    "        print(\"Running frequency analysis...\")\n",
    "        arcpy.Frequency_analysis(singlepart_fc, freq_table, \"tmpUID\")\n",
    "        print(\"frequency analysis complete\")\n",
    "\n",
    "        #print out report of multipart features found\n",
    "        with arcpy.da.SearchCursor(freq_table, ['FREQUENCY','tmpUID'],'\"FREQUENCY\" > 1') as cursor:\n",
    "            for row in cursor:\n",
    "                print(\"Multipart feature found at OID: {}\".format(row[1]))\n",
    "\n",
    "    else:\n",
    "        print(\"No multipart features found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modal_composite_01 processing, join Ped Plan - Existing Sidewalk to RCL\n",
    "## step 1\n",
    "print(\"Modal Composite 01 - Step 1 of 4\")\n",
    "\n",
    "# note: field aliases must already be present on input date (not built in code)\n",
    "# note: Ped Plan domains must already be present in scratch_gdb (not build in code)\n",
    "\n",
    "#1) copy feature classes to scratch gdb for processing\n",
    "print(\"Copying RCL to scratch gdb...\")\n",
    "RCL_temp = arcpy.CopyFeatures_management(RCL,(os.path.join(scratch_gdb_path, \"RCL_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Ped Data to scratch gdb...\")\n",
    "ped_temp = arcpy.CopyFeatures_management(Ped_Plan,(os.path.join(scratch_gdb_path, \"Ped_temp2\")))\n",
    "print(\"Done\")\n",
    "\n",
    "# #2) add & calculate line_length fields\n",
    "# print(\"Adding line length fields to datasets...\")\n",
    "# LineLength(RCL_temp)\n",
    "# LineLength(ped_temp)\n",
    "# print(\"Done\")\n",
    "\n",
    "# #4) check for multipart geometry\n",
    "# CheckMultiPart(RCL_temp)\n",
    "# CheckMultiPart(ped_temp)\n",
    "\n",
    "print(\"Modal Composite 01 - Step 1 of 4 - Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modal_composite_01 processing, join Ped Plan - Existing Sidewalk to RCL\n",
    "## step 2\n",
    "print(\"Modal Composite 01 - Step 2 of 4\")\n",
    "\n",
    "#copy RCL_temp to serve as modal_composite_01, target for modal composite joins\n",
    "print(\"Copying RCL_temp to serve as modal composite_01 join target...\")\n",
    "modal_composite_01 = arcpy.CopyFeatures_management(RCL_temp,(os.path.join(scratch_gdb_path, \"modal_composite_01a\")))\n",
    "print(\"Copying complete.\")\n",
    "\n",
    "#join fields from ped_temp to modal_composite test layer\n",
    "join_target = modal_composite_01\n",
    "join_target_field = \"SEGMENTID\"\n",
    "join_table = ped_temp\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\n",
    "    \"NBRightPed\",\"SBLeftPedZ\",\"NBRightP_1\",\"SBLeftPe_1\",\"NBRightP_2\",\n",
    "    \"SBLeftPe_2\",\"NBRightP_3\",\"SBLeftPe_3\",\"NBRightP_4\",\"SBLeftPe_4\",\n",
    "    \"NBRightP_5\",\"SBLeftPedB\",\"NBRightP_6\",\"SBLeftPe_5\",\"NBRightP_7\",\n",
    "    \"SBLeftPe_6\",\"NBRightP_8\",\"SBLeftPe_7\",\"NBRightVis\",\"SBLeftVisu\",\n",
    "    \"MidBlkXwkU\",\"MidBlkXwkC\",\"MidBlkXw_1\",\"TraffCalmi\",\"PPN_Final\",\n",
    "    \"HPI\",\"PpnNotCity\",\"line_length\"\n",
    "]\n",
    "\n",
    "#join fields\n",
    "print(\"Joining fields...\")\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#assign field aliases?\n",
    "#note: field aliases already added on input, not needed\n",
    "\n",
    "#store field/domain mapping in a dict, field name is key, domain table is value\n",
    "ped_domain_mapping = {\n",
    "    \"SBLeftPe_6\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"NBRightP_8\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightP_7\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"SBLeftPe_5\": \"OPP_domain_PedBuffTree\",\n",
    "    \"NBRightP_6\": \"OPP_domain_PedBuffTree\",\n",
    "    \"SBLeftPedB\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"NBRightP_5\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"SBLeftPe_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"NBRightP_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"SBLeftPe_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"NBRightP_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"SBLeftPe_2\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_2\": \"OPP_domain_PedZoneDrvycut\",\n",
    "    \"SBLeftPe_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"SBLeftPedZ\": \"OPP_domain_PedZoneType\",\n",
    "    \"NBRightPed\": \"OPP_domain_PedZoneType\",\n",
    "    \"SBLeftPe_7\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightVis\": \"OPP_domain_VisualInterest\",\n",
    "    \"SBLeftVisu\": \"OPP_domain_VisualInterest\",\n",
    "    \"MidBlkXwkU\": \"OPP_domain_MidBlkXwkUse\",\n",
    "    \"MidBlkXwkC\": \"OPP_domain_MidBlkXwkCond\",\n",
    "    \"MidBlkXw_1\": \"OPP_domain_MidBlkXwkCntrl\",\n",
    "    \"TraffCalmi\": \"OPP_domain_TraffCalming\"}\n",
    "\n",
    "#iterate through domain dict and assign domains to newly joined fields\n",
    "for key, value in ped_domain_mapping.items():\n",
    "    print(\"assigning domain {} to field {}\".format(value,key))\n",
    "    print(\"Done\")\n",
    "    arcpy.management.AssignDomainToField(modal_composite_01, key, value)\n",
    "    \n",
    "print(\"Domain Assignment Complete\")\n",
    "\n",
    "\n",
    "# #print out report of different line length segments (only needed if multipart QC was ran)\n",
    "# with arcpy.da.SearchCursor(modal_composite_01, ['OBJECTID','line_length', 'line_length_1'],'\"line_length\" <> \"line_length_1\"') as cursor:\n",
    "#     for row in cursor:\n",
    "#         print(\"Length difference found at OID: {}\".format(row[0]))\n",
    "        \n",
    "        \n",
    "print(\"Modal Composite 01 - Step 2 of 4 - Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modal_composite_01 join validation (optional)\n",
    "#step 3\n",
    "print(\"Modal Composite 01 - Step 3 of 4\")\n",
    "\n",
    "#copy ped_temp for join validation\n",
    "print(\"Copying ped_temp to validate join...\")\n",
    "ped_temp_join_validation = arcpy.CopyFeatures_management(ped_temp,(os.path.join(scratch_gdb_path, \"ped_temp_join_validation\")))\n",
    "\n",
    "# join rcl to modal\n",
    "join_target = ped_temp_join_validation\n",
    "join_target_field = \"SEGMENTID\"\n",
    "join_table = RCL_temp\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"SEGMENTID\"]\n",
    "\n",
    "print(\"Joining fields...\")\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#print out report of modal features with no valid join targets\n",
    "with arcpy.da.SearchCursor(ped_temp_join_validation, ['OBJECTID','SEGMENTID', 'SEGMENTID_1'],'\"SEGMENTID_1\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"No join targets in RCL for ObjectID: {}, SEGMENTID: {}\".format(row[0],row[1]))\n",
    "        \n",
    "        \n",
    "print(\"Modal Composite 01 - Step 3 of 4 - Done\")\n",
    "\n",
    "\n",
    "# MODAL FEATURES WITH NO VALID SEGMENTIDS TO JOIN TO - Stored in ped_temp_join_validation as \"SEGMENTID_1\" IS NULL\n",
    "# select records from modal that do not have corresponding SegmentIDs in RCL\n",
    "# ouput modal features to new FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## modal_composite_01 processing, join Ped Plan - Upgrades & New Features to RCL\n",
    "#step 4\n",
    "\n",
    "#note: inputs are not geometrically identical to RCL (new sidewalk data spans multiple RCL segments)\n",
    "#      join values via intersect method to split lines by segements & assign assign segmentIDs to be used as join key\n",
    "#\n",
    "\n",
    "##Additions\n",
    "# 1) assign field aliases\n",
    "# 2) handle new field names from DTS/d.alexander once available (alias,domains,etc.)\n",
    "\n",
    "#copy inputs to scratch\n",
    "#run intersect analysis on input and RCL\n",
    "#join interserct analysis outputs back to RCL, join only required fields as needed\n",
    "##\n",
    "print(\"Modal Composite 01 - Step 4 of 4\")\n",
    "\n",
    "#copy inputs to scratch gdb for processing\n",
    "print(\"Copying Ped Improve to scratch gdb...\")\n",
    "Ped_Improve_temp = arcpy.CopyFeatures_management(Ped_Improve,(os.path.join(scratch_gdb_path, \"Ped_Improve_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Ped Upgrade to scratch gdb...\")\n",
    "Ped_Add_temp = arcpy.CopyFeatures_management(Ped_Add,(os.path.join(scratch_gdb_path, \"Ped_Add_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#intesect Ped datsets with RCl\n",
    "print(\"Running Ped Improvement intersect...\")\n",
    "Ped_Improve_intersect = arcpy.Intersect_analysis([Ped_Improve_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Ped_Improve_intersect\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Running Ped Add intersect...\")\n",
    "Ped_Add_intersect = arcpy.Intersect_analysis([Ped_Add_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Ped_Add_RCL_intersect\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#join target\n",
    "join_target = modal_composite_01\n",
    "join_target_field = \"SEGMENTID\"\n",
    "\n",
    "#join Ped Improvement Interserct Results to RCL...\n",
    "print(\"Joining Ped Improvement fields...\")\n",
    "join_table = Ped_Improve_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"FID_Ped_Improve_temp\",\"ProjectID\",\"Extents\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#join Ped Additions Intersect Results to RCL...\n",
    "print(\"Joining Ped Additions fields...\")\n",
    "join_table = Ped_Add_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"FID_Ped_Add_temp\",\"ProjectID\",\"Extents\"]\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#modify fields that imported with duplicate names\n",
    "renamed_fields = {\"ProjectID\":\"Ped_Improve_ProjectID\",\n",
    "                  \"Extents\":\"Ped_Immprove_Extents\",\n",
    "                  \"ProjectID_1\":\"Ped_Add_Project_ID\",\n",
    "                  \"Extents_1\":\"Ped_Add_Extents\"}\n",
    "\n",
    "for key, value in renamed_fields.items():\n",
    "    print(\"renaming field {} to field {}\".format(key,value))\n",
    "    arcpy.AlterField_management(modal_composite_01, key, value)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "print(\"Modal Composite 01 - Step 4 of 4 - Done\")\n",
    "print(\"Modal Composite 01 - Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #modify fields that imported with duplicate names\n",
    "\n",
    "# renamed_fields = {\"ProjectID\":\"Ped_Improve_ProjectID\",\n",
    "#                   \"Extents\":\"Ped_Immprove_Extents\",\n",
    "#                   \"ProjectID_1\":\"Ped_Add_Project_ID\",\n",
    "#                   \"Extents_1\":\"Ped_Add_Extents\"}\n",
    "\n",
    "# for key, value in renamed_fields.items():\n",
    "#     print(\"renaming field {} to field {}\".format(key,value))\n",
    "#     arcpy.AlterField_management(modal_composite_01, key, value)\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_test = {\"key\":\"value\", \"key2\":\"value2\"}\n",
    "\n",
    "# for key, value in ped_domain_mapping.items():\n",
    "#     print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #iterate through domain dict and assign domains to newly joined fields\n",
    "# for key, value in ped_domain_mapping.items():\n",
    "    \n",
    "#     print(\"assigning domain {} to field {}\".format(value,key))\n",
    "#     print(\"Done\")\n",
    "#     arcpy.management.AssignDomainToField(modal_composite_01, key, value)\n",
    "    \n",
    "# print(\"Domain Assignment Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modal_Composite_02 - Bike Data Processing\n",
    "#step 1\n",
    "\n",
    "#copy Bike Plan Datsets to scratch for processing\n",
    "print(\"Copying Bike Existing to scratch gdb...\")\n",
    "Bike_Exist_temp = arcpy.CopyFeatures_management(Bike_Exist,(os.path.join(scratch_gdb_path, \"Bike_Exist_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Bike Proposed to scratch gdb...\")\n",
    "Bike_Proposed_temp = arcpy.CopyFeatures_management(Bike_Proposed,(os.path.join(scratch_gdb_path, \"Bike_Proposed_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Copying Bike ReDev to scratch gdb...\")\n",
    "Bike_ReDev_temp = arcpy.CopyFeatures_management(Bike_ReDev,(os.path.join(scratch_gdb_path, \"Bike_ReDev_temp\")))\n",
    "print(\"Done\")\n",
    "\n",
    "#store field, field aliases mappings in a dict\n",
    "bike_exist_alias = {\n",
    "    \"Fac_Name\":\"Facility Name (Bike Existing)\",\n",
    "    \"Fac_Desc\":\"Facility Description (Bike Existing)\",\n",
    "    \"DP_area\":\"DP Area (Bike Existing)\",\n",
    "    \"Fac_Type\":\"Facility Type (Bike Existing)\",\n",
    "    \"Length_mi\":\"Length (miles) (Bike Existing)\",\n",
    "    \"Owner\":\"Owner (Bike Existing)\"\n",
    "}\n",
    "\n",
    "bike_proposed_alias = {\n",
    "    \"Fac_Name\":\"Facility Name (Bike Proposed)\",\n",
    "    \"Fac_Desc\":\"Facility Description (Bike Proposed)\",\n",
    "    \"length_mi\":\"Length (miles) (Bike Proposed)\",\n",
    "    \"DP_area\":\"DP Area (Bike Proposed)\",\n",
    "    \"Project_ID\":\"Project ID (Bike Proposed)\",\n",
    "    \"Priority\":\"Priority (Bike Proposed)\",\n",
    "    \"Owner\":\"Owner (Bike Proposed)\",\n",
    "    \"Cost_Est\":\"Cost Estimate (Bike Proposed)\"\n",
    "}\n",
    "\n",
    "bike_redev_alias = {\n",
    "    \"Fac_Name\":\"Facility Name (Bike ReDev)\",\n",
    "    \"Fac_Desc\":\"Facitlity Description (Bike ReDev)\",\n",
    "    \"ProjectID\":\"Project ID (Bike ReDev)\",\n",
    "    \"DP_area\":\"DP Area (Bike ReDev)\",\n",
    "    \"Length_mi\":\"Length (miles) (Bike ReDev)\",\n",
    "    \"Fac_Type\":\"Facility Type (Bike ReDev)\",\n",
    "    \"Owner\":\"Owner (Bike ReDev)\"\n",
    "}\n",
    "\n",
    "#loop throug dicts and assign aliases & rename fields for each dataset\n",
    "\n",
    "#bike existing\n",
    "for key, value in bike_exist_alias.items():\n",
    "    new_field_name = str(key)+\"_BE\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_Exist_temp,key,new_field_name, value)\n",
    "    \n",
    "print(\"Done\")\n",
    "\n",
    "#bike proposed\n",
    "for key, value in bike_proposed_alias.items():\n",
    "    new_field_name = str(key)+\"_BP\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_Proposed_temp,key,new_field_name, value)\n",
    "    \n",
    "print(\"Done\")\n",
    "\n",
    "#bike redevelopment\n",
    "for key, value in bike_redev_alias.items():\n",
    "    new_field_name = str(key)+\"_BR\"\n",
    "    print(\"assigning alias {} to field {}, field renamed to {}\".format(value,key,new_field_name))\n",
    "    arcpy.AlterField_management(Bike_ReDev_temp,key,new_field_name, value)\n",
    "    \n",
    "print(\"Done\")\n",
    "          \n",
    "          \n",
    "print(\"Bike input processing Done\")\n",
    "\n",
    "#ADDITION \n",
    "#assign field aliases to each\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define intersection output datasets\n",
    "# Bike_Exist_RCL_intersect = os.path.join(scratch_gdb_path, \"Bike_Exist_RCL_intersect\")\n",
    "#Bike_Proposed_RCL_intersect = os.path.join(scratch_gdb_path, \"Bike_Proposed_RCL_intersect\")\n",
    "#Bike_ReDev_RCL_intersect = os.path.join(scratch_gdb_path, \"Bike_ReDev_RCL_intersect\")\n",
    "\n",
    "#intesect bike datsets with RCl\n",
    "print(\"Running Bike Exist intersect...\")\n",
    "Bike_Exist_RCL_intersect = arcpy.Intersect_analysis([Bike_Exist_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_Exist_RCL_intersect\")))\n",
    "\n",
    "print(\"Running Bike Proposed intersect...\")\n",
    "Bike_Proposed_RCL_intersect = arcpy.Intersect_analysis([Bike_Proposed_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_Proposed_RCL_intersect\")))\n",
    "\n",
    "print(\"Running Bike ReDev intersect...\")\n",
    "Bike_ReDev_RCL_intersect = arcpy.Intersect_analysis([Bike_ReDev_temp, RCL_temp],(os.path.join(scratch_gdb_path, \"Bike_ReDev_RCL_intersect\")))\n",
    "print(\"Done\")\n",
    "\n",
    "    \n",
    "#join fields from resultant to modal composite\n",
    "\n",
    "#copy modal_composite_01 as modal_composite_02, to serve as target for modal composite joins from bike layers\n",
    "print(\"Copying modal_composite_02 to serve as modal composite join target...\")\n",
    "modal_composite_02 = arcpy.CopyFeatures_management(modal_composite_01,(os.path.join(scratch_gdb_path, \"modal_composite_02a\")))\n",
    "print(\"Copying complete.\")\n",
    "\n",
    "\n",
    "#reassign domains\n",
    "\n",
    "#store field/domain mapping in a dict, field name is key, domain table is value\n",
    "ped_domain_mapping = {\n",
    "    \"SBLeftPe_6\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"NBRightP_8\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightP_7\": \"OPP_domain_PedBuffRdBuff\",\n",
    "    \"SBLeftPe_5\": \"OPP_domain_PedBuffTree\",\n",
    "    \"NBRightP_6\": \"OPP_domain_PedBuffTree\",\n",
    "    \"SBLeftPedB\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"NBRightP_5\": \"OPP_domain_PedBuffFrn\",\n",
    "    \"SBLeftPe_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"NBRightP_4\": \"OPP_domain_PedZoneInt\",\n",
    "    \"SBLeftPe_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"NBRightP_3\": \"OPP_domain_PedZoneCond\",\n",
    "    \"SBLeftPe_2\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_2\": \"OPP_domain_PedZoneDrvycut\",\n",
    "    \"SBLeftPe_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"NBRightP_1\": \"OPP_domain_PedZoneWidth\",\n",
    "    \"SBLeftPedZ\": \"OPP_domain_PedZoneType\",\n",
    "    \"NBRightPed\": \"OPP_domain_PedZoneType\",\n",
    "    \"SBLeftPe_7\": \"OPP_domain_PedBuffLight\",\n",
    "    \"NBRightVis\": \"OPP_domain_VisualInterest\",\n",
    "    \"SBLeftVisu\": \"OPP_domain_VisualInterest\",\n",
    "    \"MidBlkXwkU\": \"OPP_domain_MidBlkXwkUse\",\n",
    "    \"MidBlkXwkC\": \"OPP_domain_MidBlkXwkCond\",\n",
    "    \"MidBlkXw_1\": \"OPP_domain_MidBlkXwkCntrl\",\n",
    "    \"TraffCalmi\": \"OPP_domain_TraffCalming\"}\n",
    "\n",
    "#iterate through domain dict and assign domains to newly joined fields\n",
    "for key, value in ped_domain_mapping.items():\n",
    "    print(\"assigning domain {} to field {}\".format(value,key))\n",
    "    print(\"Done\")\n",
    "    arcpy.management.AssignDomainToField(modal_composite_02, key, value)\n",
    "    \n",
    "print(\"Domain Assignment Complete\")\n",
    "                                        \n",
    "\n",
    "#join fields from Bike Existing to modal_composite test layer\n",
    "join_target = modal_composite_02\n",
    "join_target_field = \"SEGMENTID\"\n",
    "\n",
    "\n",
    "##ADDITION\n",
    "#only join specific fields from each of the threee intersection outputs\n",
    "\n",
    "#join Bike Existing intersect results\n",
    "print(\"Joining Bike Existing fields...\")\n",
    "join_table = Bike_Exist_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BE\",\n",
    "               \"Fac_Desc_BE\",\n",
    "               \"DP_area_BE\",\n",
    "               \"Fac_Type_BE\",\n",
    "               \"Length_mi_BE\",\n",
    "               \"Owner_BE\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "#join Bike Proposed intersect results\n",
    "print(\"Joining Bike Proposed fields...\")\n",
    "join_table = Bike_Proposed_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BP\",\n",
    "               \"Fac_Desc_BP\",\n",
    "               \"length_mi_BP\",\n",
    "               \"DP_area_BP\",\n",
    "               \"Project_ID_BP\",\n",
    "               \"Fac_Type_BP\",\n",
    "               \"Priority_BP\"\n",
    "               \"Owner_BP\",\n",
    "               \"Cost_Est_BP\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "\n",
    "#join Bike ReDev intersect results\n",
    "print(\"Joining Bike ReDev fields...\")\n",
    "join_table = Bike_ReDev_RCL_intersect\n",
    "join_table_field = \"SEGMENTID\"\n",
    "join_fields = [\"Fac_Name_BR\",\n",
    "               \"Fac_Desc_BR\",\n",
    "               \"Project_ID_BR\",\n",
    "               \"DP_area_BR\",\n",
    "               \"Length_mi_BR\",\n",
    "               \"Fac_Type_BR\",\n",
    "               \"Owner_BR\"]\n",
    "\n",
    "arcpy.JoinField_management(join_target, join_target_field, join_table, join_table_field, join_fields)\n",
    "print(\"Join Fields complete.\")\n",
    "\n",
    "print(\"Bike Processing Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list records of different line length\n",
    "\n",
    "#print out report of multipart features found\n",
    "with arcpy.da.SearchCursor(ped_temp_join_validation, ['OBJECTID','SEGMENTID', 'SEGMENTID_1'],'\"SEGMENTID_1\" IS NULL') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"No join targets in RCL for ObjectID: {}, SEGMENTID: {}\".format(row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get fields\n",
    "# fields = arcpy.ListFields(Bike_Exist_temp)\n",
    "fields = arcpy.ListFields(Bike_ReDev_RCL_intersect)\n",
    "# fields = arcpy.ListFields(Bike_ReDev_temp)\n",
    "\n",
    "fieldinfo = arcpy.FieldInfo()\n",
    "\n",
    "\n",
    "for field in fields:\n",
    "    #print(field.name, field.aliasName, field.type)\n",
    "    print(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PED re-copy to scratch - rerun as needed\n",
    "\n",
    "#1) copy feature classes to scratch gdb for processing\n",
    "ped_temp = arcpy.CopyFeatures_management(Ped_Plan,(os.path.join(scratch_gdb_path, \"Ped_temp\")))\n",
    "\n",
    "#2) add & calculate line_length fields\n",
    "LineLength(ped_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multipart function testing\n",
    "\n",
    "dataset = ped_temp\n",
    "   \n",
    "#get count of input features\n",
    "input_count = arcpy.GetCount_management(dataset)\n",
    "print(str(input_count) + \" records in input dataset\")\n",
    "\n",
    "#add tempID field to input dataset\n",
    "arcpy.AddField_management(dataset, \"tmpUID\",\"LONG\")\n",
    "print(\"tmpUID field added to input dataset\")\n",
    "\n",
    "#determine OID field of input dataset\n",
    "OID_field_name = arcpy.Describe(dataset).OIDFieldName\n",
    "print(\"OID = \" + str(OID_field_name))\n",
    "\n",
    "#calculate OID to tmpID\n",
    "print(\"Calculating OID to tmpUID...\")\n",
    "arcpy.CalculateField_management(dataset,\"tmpUID\",\"!\" + OID_field_name +\"!\")\n",
    "print(\"OID calculated to tmpUID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define singlepart dataset\n",
    "singlepart_fc_name = str(dataset)+\"_singlepart\"\n",
    "singlepart_fc = os.path.join(scratch_gdb_path, singlepart_fc_name)\n",
    "\n",
    "#delete singlepart dataset if it already exists\n",
    "if arcpy.Exists(singlepart_fc):\n",
    "    print(\"Singlepart dataset already exists, deleting...\")\n",
    "    arcpy.Delete_management(singlepart_fc)\n",
    "    print(\"Singlepart dataset deleted\")\n",
    "\n",
    "#split input features into singlepart dataset\n",
    "print(\"Splitting input dataset into singlepart feature...\")\n",
    "arcpy.MultipartToSinglepart_management(dataset,singlepart_fc)\n",
    "print(\"input exploded to singlepart\" + singlepart_fc_name)\n",
    "\n",
    "#get feature count of output \n",
    "output_count = arcpy.GetCount_management(singlepart_fc)\n",
    "print(str(output_count)+ \" records in singlepart FC\")\n",
    "\n",
    "# if multipart features found, run freq and get ID of multipart feature\n",
    "if input_count != output_count:\n",
    "    print(\"Multipart features found.\")\n",
    "    print(\"{0} records in input, {1} records in singlepart output.\".format(input_count, output_count))\n",
    "\n",
    "    #define frequency table\n",
    "    freq_table_name = str(dataset)+\"_freq\"\n",
    "    freq_table = os.path.join(scratch_gdb_path, freq_table_name)\n",
    "\n",
    "    #delete freq table if it already exists\n",
    "    if arcpy.Exists(freq_table):\n",
    "        print(\"freq table exists, deleting...\")\n",
    "        arcpy.Delete_management(freq_table)\n",
    "        print('freq table deleted')\n",
    "\n",
    "    #run frequency analysis on singlepart dataset\n",
    "    print(\"Running frequency analysis...\")\n",
    "    arcpy.Frequency_analysis(singlepart_fc, freq_table, \"tmpUID\")\n",
    "    print(\"frequency analysis complete\")\n",
    "\n",
    "    #print out report of multipart features found\n",
    "    with arcpy.da.SearchCursor(freq_table, ['FREQUENCY','tmpUID'],'\"FREQUENCY\" > 1') as cursor:\n",
    "        for row in cursor:\n",
    "            print(\"Multipart feature found at OID: {}\".format(row[1]))\n",
    "\n",
    "else:\n",
    "    print(\"No multipart features found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with arcpy.da.SearchCursor(freq_table, ['FREQUENCY','tmpUID'],'\"FREQUENCY\" > 1') as cursor:\n",
    "    for row in cursor:\n",
    "        print(\"Multipart feature found at OID: {}\".format(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
